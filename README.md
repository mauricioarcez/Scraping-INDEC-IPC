# Scraper Automatizado de Precios por regiones INDEC
Este proyecto resuelve la complejidad estructural de los informes oficiales de precios de alimentos del [INDEC](https://www.indec.gob.ar/indec/web/Nivel4-Tema-3-5-31), donde los datos se publican en excels desorganizados con formatos inconsistentes, saltos de l铆nea, contenido que cambia constantemente el nombre de sus archivos y renderizado din谩mico con js que complica su obtencion automatizada. 

Mediante un sistema de scraping avanzado con Playwright (para superar las barreras de JavaScript), combinado con un pipeline de limpieza automatizada en Python, convertimos estas fuentes inutilizables en datasets analizables con informacion actualizada todos los meses.  

**Resultado**: Informaci贸n lista y actualizada para an谩lisis en .CSV, permitiendo estudios de inflaci贸n, tendencias regionales y evoluci贸n hist贸rica con la fuente oficial pero sin el trabajo manual. 


##  Requisitos
- Python 3.10 o superior
- Dependencias listadas en requirements.txt:

##  Instalaci贸n

1. Clonar el repositorio.
2. Crear y activar entorno virtual.
3. Instalar dependencias:
```bash
pip install -r requirements.txt
playwright install
```

##  Uso

### **Ejecuci贸n Autom谩tica (Recomendada)**
El sistema se ejecuta autom谩ticamente mediante GitHub Actions:
 - Workflow Mensual: Actualiza la fecha del pr贸ximo informe (se ejecuta el d铆a 1 de cada mes)
 - Workflow Diario: Verifica diariamente si es la fecha programada para el scraping


### **Ejecuci贸n Manual**

Para ejecutar el scraping manualmente:
```bash
python -m src.main
```
## 锔 GitHub Actions Workflow
### El proyecto utiliza dos workflows automatizados:**
1. **Update Next Scraping Date**
    - Se ejecuta el primer d铆a de cada mes
    - Obtiene la pr贸xima fecha de informe del INDEC
    - Actualiza el archivo next_date.txt

2. **Scrape on Target Date**
    - Verifica diariamente si es la fecha programada
    - Ejecuta el scraping solo cuando coincide con next_date.txt
    - Guarda los datos actualizados en el repositorio

##  Proceso de Datos

1. Obtenci贸n din谩mica de URL del archivo Excel
2. Extracci贸n de datos de la hoja "Nacional"
3. Limpieza y transformaci贸n de datos:
    - Identificaci贸n de encabezados
    - Procesamiento de fechas y precios
    - Conversi贸n de formato ancho a largo
    - Generaci贸n de IDs 煤nicos por producto
    - Validaci贸n de datos
4. Guardado de archivos procesados en formato CSV
5. Actualizaci贸n autom谩tica del repositorio

##  Notas

- La ejecuci贸n autom谩tica usa UTC (ajustar zonas horarias si es necesario)
- Los datos se actualizan en la rama principal (main)
- El workflow puede ejecutarse manualmente desde GitHub Actions
- Historial de ejecuciones disponible en la pesta帽a "Actions"

##  Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue primero para discutir los cambios que te gustar铆a hacer.

##  Desarrollado por Mauricio Arce | [Linkedin](https://www.linkedin.com/in/mauricioarcez/)
