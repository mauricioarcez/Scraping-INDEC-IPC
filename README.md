<<<<<<< HEAD
# Scraper de Precios INDEC
Este proyecto automatiza la recolecci贸n y procesamiento de datos de precios desde el INDEC (Instituto Nacional de Estad铆stica y Censos de Argentina).

##  Requisitos
- Python 3.10 o superior
- Dependencias listadas en requirements.txt:

##  Instalaci贸n

1. Clonar el repositorio.
2. Crear y activar entorno virtual.
3. Instalar dependencias:
```bash
pip install -r requirements.txt
playwright install
```

##  Uso

### Ejecuci贸n Manual

Para ejecutar el scraping manualmente:
```bash
python -m src.main
```

##  Proceso de Datos

   - Obtiene la URL del archivo Excel de forma dinamica, adelantandose a cambios en nombres de archivo.
   - Extrae datos de la hoja "Nacional"
   - Limpieza de datos, Identificaci贸n de encabezados, Procesamiento de fechas y precios.
   - Melt de archivo ancho a largo. 
   - Generaci贸n de IDs 煤nicos por producto
   - Validacion de datos.
   - Guardado de archivo limpio en formato .csv
   - Obtencion de la proxima fecha de informe.
   - Actualiza el cronograma de ejecuci贸n
   - Se ejecuta autom谩ticamente en la fecha del informe
   - Guarda y commitea los cambios del nuevo informe

##  Notas

- Los datos se actualizan autom谩ticamente seg煤n el calendario del INDEC
- Los archivos CSV se guardan en el repositorio
- El workflow se puede ejecutar manualmente desde GitHub Actions si es necesario

##  Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue primero para discutir los cambios que te gustar铆a hacer.

##  Desarrollado por Mauricio Arce. 
=======
# Scraping y Normalizaci贸n de Datos de canasta basica IPC - INDEC (2017- actualidad) - por Regiones

Este proyecto realiza la extracci贸n, transformaci贸n y carga de datos (ETL) del ndice de Precios al Consumidor (IPC) por regiones de la canasta b谩sica del **INDEC**, abarcando el per铆odo desde 2017 y manejando la carga de nuevos datos para mantenerla actualizada.  

El scraping y la normalizaci贸n se realizaron completamente en un cuaderno de Jupyter, destacando el uso de t茅cnicas avanzadas para superar las limitaciones del sitio web del INDEC, como el renderizado de contenido din谩mico con **JavaScript**.  
**Ahora el proceso es completamente autom谩tico**: con un solo clic, puedes actualizar la informaci贸n, incluso si el INDEC agrega m谩s tablas o modifica la estructura de los datos.  

[**Dataset en Alphacast**](https://www.alphacast.io/datasets/prueba-tecnica-completada-43861)  

---

## **Caracter铆sticas Destacadas del Proyecto**  

1. **Automatizaci贸n completa:**  
   - El proceso se encuentra automatizado en su totalidad, desde la extracci贸n hasta el guardado en CSV o la carga en Alphacast.  
   - Con un solo clic, puedes obtener los datos actualizados del INDEC, sin importar si se agregan nuevas tablas o se modifica la estructura del sitio.  

2. **Desaf铆o del scraping:**  
   - El HTML del INDEC es renderizado din谩micamente con JavaScript, lo que imposibilita el scraping tradicional.  
   - Se implementaron soluciones avanzadas para obtener los datos de manera confiable, sin depender de URLs directas, que suelen cambiar con frecuencia.  

3. **Transformaciones avanzadas de datos:**  
   - Los datos descargados estaban en un **formato horizontal** y desestructurado, sin tablas ni columnas organizadas.  
   - Se realizaron transformaciones profundas para estructurar los datos de manera adecuada para su an谩lisis con **Pandas**.  
   - Fechas mal formateadas y columnas desordenadas fueron normalizadas.  

4. **Manejo de datos faltantes y errores:**  
   - Se emplearon t茅cnicas como la interpolaci贸n y el relleno de valores nulos utilizando datos de meses anteriores y posteriores.  
   - Validaci贸n de datos para garantizar integridad y coherencia.  

5. **Formato CSV para analisis:**  
   - Los datos transformados se guardan en formato CSV. O puedes facilitar tus claves para subirlos a Alphacast y facilitar su an谩lisis y visualizaci贸n.  

---

## **Estructura del Proyecto**  

- **`.gitignore`:** Archivo para excluir archivos y directorios como el entorno virtual.  
- **`explicacion.ipynb`:** Cuaderno Jupyter que detalla el scraping, la normalizaci贸n y el an谩lisis de los datos paso a paso.  
   - **Fuente de datos:** [INDEC - IPC](https://www.indec.gob.ar/indec/web/Nivel4-Tema-3-5-31).  
- **`requirements.txt`:** Librer铆as necesarias para ejecutar el cuaderno.  

---

## **Instalaci贸n y Uso**  

Para ejecutar el proyecto en tu entorno local:  

1. **Clonar el repositorio:**  
   ```bash
   git clone https://github.com/mauricioarcez/reto-tecnico.git

2. **Crear un entorno virtual:**

   ```bash
    python -m venv venv
   
3. **Activar el entorno virtual:**
  En Windows:
   ```bash
    venv\Scripts\activate
   
4. **Instalar las dependencias:**
   ```bash
    pip install -r requirements.txt
   
Ejecutar el cuaderno Jupyter: explicacion.ipynb
>>>>>>> b7c06fe22400c80d5faa44d71b151770d61fe8c8
